{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e56bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import r2_score\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee1897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sp500_list.txt\", \"r\") as f:\n",
    "    sp500_list = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "913b809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfdata = pd.read_csv(\"market_data.csv\", index_col=0, low_memory=False)\n",
    "rfdata = rfdata.drop(rfdata.index[[0,1]])\n",
    "rfdata.columns = pd.MultiIndex.from_arrays([[\"Adj Close\"]*503 + [\"Volume\"]*503, sp500_list*2])\n",
    "rfdata.index = pd.core.indexes.datetimes.DatetimeIndex(rfdata.index)\n",
    "rfdata = rfdata.astype(float)\n",
    "\n",
    "data = rfdata[\"Adj Close\"]\n",
    "data = data.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd8bf2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "25860394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy as dc\n",
    "\n",
    "def prepare_dataframe_for_lstm(df, n_steps):\n",
    "    df = dc(df)\n",
    "    for j in range(1, n_steps+1):\n",
    "        df[f'Adj Close(t-{j})'] = df['Adj Close'].shift(j)\n",
    "        df.dropna(inplace=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e2e265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70c5dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_stacked_layers):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_stacked_layers = num_stacked_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_stacked_layers, \n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d816d787",
   "metadata": {},
   "outputs": [],
   "source": [
    "    class LSTM(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, num_stacked_layers):\n",
    "            super().__init__()\n",
    "            self.hidden_size = hidden_size\n",
    "            self.num_stacked_layers = num_stacked_layers\n",
    "\n",
    "            self.lstm = nn.LSTM(input_size, hidden_size, num_stacked_layers, batch_first=True)\n",
    "        \n",
    "            self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            batch_size = 16\n",
    "            h0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size)\n",
    "            c0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size)\n",
    "        \n",
    "            out, _ = self.lstm(x, (h0, c0))\n",
    "            out = self.fc(out[:, -1, :])\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2279d340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46min 8s\n",
      "Wall time: 32min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_train_lstm = []\n",
    "score_test_lstm = []\n",
    "lstm_pred = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "for i in data.columns:\n",
    "    frame = data[i].pct_change().dropna().to_frame()\n",
    "    frame = frame.rename(columns={ i : \"Adj Close\"})\n",
    "\n",
    "    def prepare_dataframe_for_lstm(df, n_steps):\n",
    "        df = dc(df)\n",
    "    \n",
    "        for j in range(1, n_steps+1):\n",
    "            df[f'Adj Close(t-{j})'] = df['Adj Close'].shift(j)\n",
    "        df.dropna(inplace=True)\n",
    "        return df\n",
    "    lookback = 16\n",
    "    shifted_df = prepare_dataframe_for_lstm(frame, lookback)\n",
    "    \n",
    "    y = shifted_df[\"Adj Close\"]\n",
    "    X = shifted_df.drop(columns =[\"Adj Close\"])\n",
    "    \n",
    "    X_train = X[\"2013-01-01\":\"2023-01-01\"].to_numpy()\n",
    "    X_train = dc(np.flip(X_train, axis=1))\n",
    "    X_test = X[\"2023-01-01\":].to_numpy()\n",
    "    X_test = dc(np.flip(X_test, axis=1))\n",
    "    y_train = y[\"2013-01-01\":\"2023-01-01\"].to_numpy()\n",
    "    y_test = y[\"2023-01-01\":].to_numpy()\n",
    "    \n",
    "    X_train = X_train.reshape((-1, lookback, 1))\n",
    "    X_test = X_test.reshape((-1, lookback, 1))\n",
    "    y_train = y_train_np.reshape((-1, 1))\n",
    "    y_test = y_test_np.reshape((-1, 1))\n",
    "\n",
    "    X_train = torch.tensor(X_train).float()\n",
    "    y_train = torch.tensor(y_train).float()\n",
    "    X_test = torch.tensor(X_test).float()\n",
    "    y_test = torch.tensor(y_test).float()\n",
    "    \n",
    "    train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "    test_dataset = TimeSeriesDataset(X_test, y_test)\n",
    "    \n",
    "    batch_size=16\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = LSTM(1, 16, 1)\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.00005)\n",
    "    \n",
    "    for epoch in range(5):\n",
    "        for seqs, labels in train_loader:\n",
    "            # batch size, seq length, num features\n",
    "            seqs = seqs.view(16, len(seqs), 1)\n",
    "            # Get model outputs\n",
    "            outputs = model(seqs).squeeze()\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    with torch.no_grad():    \n",
    "        predicted_train = model(X_train.to(device)).to('cpu').numpy()\n",
    "        predicted_test = model(X_test.to(device)).to('cpu').numpy()\n",
    "            \n",
    "    score_test_lstm.append(r2_score(np.array(y_test).reshape(250), predicted_test.reshape(250)))\n",
    "    score_train_lstm.append(r2_score(np.array(y_train).reshape(2518), predicted_train.reshape(2518)))\n",
    "                                                  \n",
    "    lstm_pred[i] = predicted_test.reshape(250)\n",
    "    \n",
    "\n",
    "lstm_score = pd.DataFrame({\"score_train\" : score_train_lstm, \"score_test\": score_test_lstm}, data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "882fecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm_score.to_csv(\"LSTMscore.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d2cffe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm_pred.to_csv(\"LSTMpred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e3ab59ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_train</th>\n",
       "      <th>score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TMUS</th>\n",
       "      <td>0.005299</td>\n",
       "      <td>-0.018719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TFC</th>\n",
       "      <td>0.004474</td>\n",
       "      <td>-0.003277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JNJ</th>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.002095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VRSN</th>\n",
       "      <td>0.002824</td>\n",
       "      <td>-0.012020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DVN</th>\n",
       "      <td>0.002766</td>\n",
       "      <td>-0.003264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDLZ</th>\n",
       "      <td>0.002640</td>\n",
       "      <td>-0.003151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMY</th>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.000246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AON</th>\n",
       "      <td>0.002056</td>\n",
       "      <td>-0.009574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMM</th>\n",
       "      <td>0.002035</td>\n",
       "      <td>-0.007552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WTW</th>\n",
       "      <td>0.002027</td>\n",
       "      <td>-0.004613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ULTA</th>\n",
       "      <td>0.001873</td>\n",
       "      <td>-0.013245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>0.001840</td>\n",
       "      <td>-0.000621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADSK</th>\n",
       "      <td>0.001813</td>\n",
       "      <td>-0.002952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AXP</th>\n",
       "      <td>0.001773</td>\n",
       "      <td>-0.004260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYK</th>\n",
       "      <td>0.001753</td>\n",
       "      <td>-0.023747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HON</th>\n",
       "      <td>0.001745</td>\n",
       "      <td>-0.004295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PH</th>\n",
       "      <td>0.001743</td>\n",
       "      <td>-0.014137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APH</th>\n",
       "      <td>0.001734</td>\n",
       "      <td>-0.008396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRM</th>\n",
       "      <td>0.001732</td>\n",
       "      <td>-0.016275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CPB</th>\n",
       "      <td>0.001670</td>\n",
       "      <td>-0.001875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAA</th>\n",
       "      <td>0.001644</td>\n",
       "      <td>-0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELV</th>\n",
       "      <td>0.001609</td>\n",
       "      <td>-0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVGO</th>\n",
       "      <td>0.001565</td>\n",
       "      <td>-0.028759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DD</th>\n",
       "      <td>0.001561</td>\n",
       "      <td>-0.004950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ES</th>\n",
       "      <td>0.001529</td>\n",
       "      <td>-0.006858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GILD</th>\n",
       "      <td>0.001456</td>\n",
       "      <td>-0.002673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.001389</td>\n",
       "      <td>-0.008729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WRB</th>\n",
       "      <td>0.001293</td>\n",
       "      <td>-0.007175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UPS</th>\n",
       "      <td>0.001281</td>\n",
       "      <td>-0.013355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSI</th>\n",
       "      <td>0.001272</td>\n",
       "      <td>-0.005858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPC</th>\n",
       "      <td>0.001164</td>\n",
       "      <td>-0.010300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JKHY</th>\n",
       "      <td>0.001153</td>\n",
       "      <td>-0.003467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCO</th>\n",
       "      <td>0.001147</td>\n",
       "      <td>-0.004484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BG</th>\n",
       "      <td>0.001133</td>\n",
       "      <td>-0.000675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRK</th>\n",
       "      <td>0.001116</td>\n",
       "      <td>-0.003480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRMN</th>\n",
       "      <td>0.001093</td>\n",
       "      <td>-0.009234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BXP</th>\n",
       "      <td>0.001074</td>\n",
       "      <td>-0.007799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMT</th>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.000825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GS</th>\n",
       "      <td>0.001053</td>\n",
       "      <td>-0.004495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MNST</th>\n",
       "      <td>0.001047</td>\n",
       "      <td>-0.004297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WDC</th>\n",
       "      <td>0.001028</td>\n",
       "      <td>-0.004443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FCX</th>\n",
       "      <td>0.000960</td>\n",
       "      <td>-0.004040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LLY</th>\n",
       "      <td>0.000917</td>\n",
       "      <td>-0.009566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXC</th>\n",
       "      <td>0.000910</td>\n",
       "      <td>-0.004359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EW</th>\n",
       "      <td>0.000871</td>\n",
       "      <td>-0.006956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMR</th>\n",
       "      <td>0.000835</td>\n",
       "      <td>-0.006602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAP</th>\n",
       "      <td>0.000794</td>\n",
       "      <td>-0.013137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KR</th>\n",
       "      <td>0.000772</td>\n",
       "      <td>-0.002054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APD</th>\n",
       "      <td>0.000768</td>\n",
       "      <td>-0.001837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PNR</th>\n",
       "      <td>0.000698</td>\n",
       "      <td>-0.008186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score_train  score_test\n",
       "TMUS     0.005299   -0.018719\n",
       "TFC      0.004474   -0.003277\n",
       "JNJ      0.003690    0.002095\n",
       "VRSN     0.002824   -0.012020\n",
       "DVN      0.002766   -0.003264\n",
       "MDLZ     0.002640   -0.003151\n",
       "BMY      0.002081    0.000246\n",
       "AON      0.002056   -0.009574\n",
       "MMM      0.002035   -0.007552\n",
       "WTW      0.002027   -0.004613\n",
       "ULTA     0.001873   -0.013245\n",
       "L        0.001840   -0.000621\n",
       "ADSK     0.001813   -0.002952\n",
       "AXP      0.001773   -0.004260\n",
       "SYK      0.001753   -0.023747\n",
       "HON      0.001745   -0.004295\n",
       "PH       0.001743   -0.014137\n",
       "APH      0.001734   -0.008396\n",
       "CRM      0.001732   -0.016275\n",
       "CPB      0.001670   -0.001875\n",
       "MAA      0.001644   -0.003681\n",
       "ELV      0.001609   -0.000430\n",
       "AVGO     0.001565   -0.028759\n",
       "DD       0.001561   -0.004950\n",
       "ES       0.001529   -0.006858\n",
       "GILD     0.001456   -0.002673\n",
       "RF       0.001389   -0.008729\n",
       "WRB      0.001293   -0.007175\n",
       "UPS      0.001281   -0.013355\n",
       "MSI      0.001272   -0.005858\n",
       "GPC      0.001164   -0.010300\n",
       "JKHY     0.001153   -0.003467\n",
       "MCO      0.001147   -0.004484\n",
       "BG       0.001133   -0.000675\n",
       "MRK      0.001116   -0.003480\n",
       "GRMN     0.001093   -0.009234\n",
       "BXP      0.001074   -0.007799\n",
       "WMT      0.001058    0.000825\n",
       "GS       0.001053   -0.004495\n",
       "MNST     0.001047   -0.004297\n",
       "WDC      0.001028   -0.004443\n",
       "FCX      0.000960   -0.004040\n",
       "LLY      0.000917   -0.009566\n",
       "EXC      0.000910   -0.004359\n",
       "EW       0.000871   -0.006956\n",
       "EMR      0.000835   -0.006602\n",
       "TAP      0.000794   -0.013137\n",
       "KR       0.000772   -0.002054\n",
       "APD      0.000768   -0.001837\n",
       "PNR      0.000698   -0.008186"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_score.sort_values(by='score_train', ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f317c5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
